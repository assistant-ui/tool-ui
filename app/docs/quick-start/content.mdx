import { DocsHeader } from "../_components/docs-header";

<DocsHeader title="Quick Start" />

Get Tool UI working in your app in minutes. This guide uses assistant-ui (recommended) for the best experience.


## Setup

<Steps>

<Step title="1. Initialize assistant-ui">

Set up the assistant-ui runtime provider that manages the connection between your frontend and backend. This handles message streaming, tool execution, and state management.

```tsx
"use client";
import { AssistantRuntimeProvider } from "@assistant-ui/react";
import { useChatRuntime, AssistantChatTransport } from "@assistant-ui/react-ai-sdk";

function App() {
  const runtime = useChatRuntime({
    transport: new AssistantChatTransport({ api: "/api/chat" }),
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      {/* Your chat UI */}
    </AssistantRuntimeProvider>
  );
}
```

</Step>

<Step title="2. Define a backend tool">

Create a tool on your server that the LLM can call. The tool returns structured JSON that matches a Tool UI component schema. Here we're creating a link preview tool that returns data for the MediaCard component.

```ts
import { streamText, tool } from "ai";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";
// Import the schema from the Tool UI package
import { serializableMediaCardSchema } from "@tool-ui/media-card";

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai("gpt-4o"),
    messages,
    tools: {
      previewLink: tool({
        description: "Show a preview card for a URL",
        inputSchema: z.object({ url: z.string().url() }),
        outputSchema: serializableMediaCardSchema,
        async execute({ url }) {
          // In production, you'd fetch real metadata here
          return {
            id: "link-1",
            kind: "link",
            href: url,
            title: "Example Site",
            description: "A description of the linked content",
            thumb: "https://example.com/image.jpg",
          };
        },
      }),
    },
  });

  return result.toUIMessageStreamResponse();
}
```

</Step>

<Step title="3. Register the Tool UI">

Connect your backend tool to a frontend component. When the LLM calls the `previewLink` tool, assistant-ui will automatically render the MediaCard component with the returned data.

```tsx
import { makeAssistantToolUI } from "@assistant-ui/react";
import { MediaCard, type SerializableMediaCard } from "@tool-ui/media-card";

export const PreviewLinkUI = makeAssistantToolUI<
  { url: string },
  SerializableMediaCard
>({
  toolName: "previewLink",  // Must match backend tool name
  render: ({ result }) => (
    <MediaCard {...result} maxWidth="420px" />
  ),
});

// Register in your app
function App() {
  return (
    <AssistantRuntimeProvider runtime={runtime}>
      <PreviewLinkUI />
      <Thread />
    </AssistantRuntimeProvider>
  );
}
```

That's it! When a user asks the assistant to preview a link, it will call your tool and render a beautiful MediaCard component.

</Step>

</Steps>


## Installation

```sh
npx assistant-ui@latest init
```

Or install manually:

```sh
pnpm add @assistant-ui/react @assistant-ui/react-ai-sdk ai @ai-sdk/openai zod
```

Add your API key:

```env
OPENAI_API_KEY=sk-...
```


## Other frameworks

Tool UI components work with any React app. Without assistant-ui, you'll need to manually parse tool outputs and render components. For the best experience, we recommend using assistant-ui.


## Runtime options

assistant-ui supports multiple runtimes: AI SDK, LangGraph, LangServe, Mastra, or custom backends. The examples above use AI SDK v5.


## Next steps

- [Explore components](/docs/data-table) – Data Table, Media Card, Decision Prompt, Social Post
- [UI Guidelines](/docs/design-guidelines) – Learn the interaction patterns
- [Examples](https://github.com/assistant-ui/assistant-ui/tree/main/examples) – Full implementations
